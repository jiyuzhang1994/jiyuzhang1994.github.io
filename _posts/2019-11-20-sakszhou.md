---
layout: default
permalink: /sakszhou/
title: Derandomize BPL:BPL is in L^{3/2}
tags: Study
---

* [An Algorithm for Estimating Success Probability via Nisan's PRG](#algo)

Given a ROBP of our interest, there is a trivial algorithm to compute the $(i,j)$-th entry of one layer's transition matrix $M$: for input $(i,j)$, simply enumerates all transition strings $$\{0,1\}^m$$ and counts the number of strings that lead to $j$, then divide this number by $2^m$. This algorithm uses space $O(d+m)$.  

To derandomize $BPL$, it's enough to show a deterministic algorithm that runs in small space and estimates the $(i, j)$-th  entry with error $1/d$ in the matrix $M^{2^r}$. We say this algorithm approximates $M^{2^r}$. 

For reasons above, from now on we phrase everything in terms of matrix exponentiation.  

**Fact.** The repeated squaring algorithm computes exact $M^{2^r}$ with space $O(rd)$.  

From Nisan's generator, we should see that it implicitly gives an algorithm for approximating matrix exponentiation. Let's show the algorithm below.


## <a name="algo"></a> 1. An Algorithm for Approximating Matrix Exponentiation via Nisan's PRG 

The algorithm starts by randomly picking a set of hash functions and store these functions, we call the space we need for this purpose the *random bit complexity*.  It then starts to feed the pseudorandom bits, produced by computing these hash functions, to the ROBP and computes using the trivial counting algorithm. We call the space for this purpose the *processing space complexity*. The following algorithm from [1] captures the processing step:  

**Lemma 4.1** (Saks and Zhou; Nisan) For a $d\times d$ matrix $M$ and integers $r, m$, there is an algorithm PRS(M, r, m; h) (meaning *Pseudorandom Repeated Squaring*) that takes a random string $$h\in \{0,1\}^{2m\cdot r}$$, runs in space $O(m+r+\log d)$ and, if $m= O(\log d)$, approximates the matrix $M^{2^r}$ with error $O(1/d)$.

Therefore, if we use Nisan's generator and apply the algorithm in Lemma 4.1 in a straightforward way, we have an algorithm for deterministically simulating $BPL$ in space $O(\log n^2)$ (for random bit complexity) + $O(\log n)$ (for processing space complexity) = $O(\log n^2)$. For comparison, the recursive repeated squaring algorithm has processing space complexity $O(\log n^2)$.   

The main idea of Saks and Zhou for proving $BPL\subseteq L^{3/2}$ is just, by combining these two algorithms (*PRS + Recursive Repeated Squaring*) in a sophisticated way, so the final random bit complexity falls down to $O(\log n^{3/2})$ and the processing space complexity becomes $O(\log n^{3/2})$.  

## 2. Saks and Zhou's algorithm  

As mentioned in the last section, we gonna combine PRS and the repeated squaring algorithm in a "sophisticated" way. To illustrate this way of combining, we first define some operators for real numbers in $[0,1]$ and similarly, for matrix.  

**Definition 2.1** (*Perturbation Operator*) a perturbation opertaor $\Sigma_\delta$ is a function mapping nonnegative real number $z\in [0,1]$ to $$\Sigma_\delta = \max \{z-\delta, 0\}$$. The operator applies to matrices by applying it entry by entry to the matrix.  

**Definition 2.2** (*Truncation Operator*) for a positive integer $t$, a truncation operator $\lfloor\  \rfloor_t$ is a function that, for a nonnegative real number $z$, truncating the binary expansion of $z$ after $t$ binary digits. That is, $\lfloor z\rfloor _t = 2^{-t} \lfloor 2^t z\rfloor$. Again, the operator applies to matrices by applying it entry by entry to the matrix.  

Some facts for applying these operators on matrices will be useful for our purpose:  

**Proposition 2.3** For $M, N \in R^d\times R^d$,

1. $\lvert\lvert M - \lfloor M \rfloor_t \rvert\rvert \leq d\cdot 2^{-t}$  
2. $\lvert\lvert M - \Sigma_\delta M  \rvert\rvert \leq d\cdot \delta$  
3. $\lvert\lvert \Sigma_\delta M - \Sigma_\delta N\rvert\rvert \leq \lvert\lvert M - N\rvert\rvert$  

We now start to give an overview of Saks and Zhou's algorithm. The idea is, to apply PRS recursively.  

Let $A^r(M)$ be the matrix obtained by repeatedly squaring $M$ for $r$ times, i.e. $A^r(M) = M^{2^r}$. Consider $A^r(M) = A^{r_1\cdot r_2}(M) = A^{r_2}(A^{r_1}(M))$ where $r_1 \cdot r_2 = r$, if we apply PRS recursively, that is, we repeatedly compute $A^{r_1}$ for $r_2$ times. Now the random bit complexity will be $r_2\cdot r_1 m = O(rd)$ and the processing space complexity is $r_2\cdot O(d)$. Therefore the random bit complexity has not been improved, and we paid additional cost for processing space complexity.  

The additional idea is to feed the same random bits for each level of these PRSs, so we can reduce the random bit complexity, and if necessary we are willing to pay more processing space complexity. However it's hard to prove that there exists such a sequence of random bits that works for every level.  

Consider the repeated squaring sequence 



## References  

[1] Michael Saks and Shiyu Zhou, "BPHSPACE(S) âŠ† DSPACE(S^3/2)". http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.225.8850&rep=rep1&type=pdf 

