---
layout: default
permalink: /dpsurvey/
title: 差分隐私 Differential Privacy
tags: Cryptography
---

## 问题背景

在现在的大数据时代，很多互联网公司将收集的用户使用信息或记录保存于数据库，并通过数据分析手段来提高用户的体验。 在这个过程中不可避免地就会出现隐私泄露的问题。数据集中可能包含有用户的医疗诊断信息，个人消费偏好等信息，个人的此类信息遭遇泄露的话，难免不会被有心人利用并导致对个人不利的后果。

一个比较典型的隐私泄露例子发生在06年的时候，Netflix（美国一家媒体服务提供商） 发起了一个有100万美金奖励的数据挖掘竞赛。 他们发布了一组关于用户浏览记录的数据集， 如果有人能通过这份数据集使他们的推荐系统的效能提高10%就可获得奖金。 当然，为了保护用户隐私，他们声称已经把包含用户ID的信息都删除以实现匿名化。 问题在于，这样是否真的已经将用户的信息隐藏起来？答案是否定的。来自 UT Austin 的 Arvind Narayanan 和 Vitaly Shmatikov 的工作[]通过把已公布的数据库与 Internet Movie Database (IMDb) 结合起来，实现了一定程度反匿名化，暴露出了用户的信息。

可以举一个简单的例子来从直觉上解释怎么做到反匿名的过程: 假如有一个数据库 $A$，里面包含了一些用户的 性别，出生日期，邮政编码，或是在一段时间内看过某场电影，但没有姓名，身份证信息。而另外一个数据库 $B$ 里包含一些用户的姓名，性别，邮政编码，出生日期，医疗信息，住址。 这样，通过对比这两个公开的数据库（比如相同的邮编和出生日期），我们可以很容易地猜出 $B$ 中的哪些人对应 $A$ 中的哪些信息。这样的攻击我们称为**链接攻击**。  

另外一个例子解释攻击者可以通过不同的询问方式来问出私人信息。攻击者第一次进行这样的提问：“在2001年，P大学的大一新生有多少人家庭年收入35万以上？” 他得到准确答案是200。他接着提问：“在2002年， P大学的大二学生有多少人家庭年收入在35万以上？” 这次他得到答案是199。 于是他通过另外一种方式得知一名叫张知秋的同学在大二时退学了（比如查询在校学生表格）。 这样他可以得出结论：张知秋同学的家庭年收入在35万以上。这样的攻击我们称为**差分攻击**。

差分隐私就是为了防止这样的攻击而提出，它的最终目的是使得数据分析者能对数据库进行**隐私保护的数据分析**。在差分隐私机制中，我们希望通过对数据库返回的值进行一定的处理，从而使得返回结果具有一定的随机性，但大致保持一定的精确度。这样，就能防止攻击者通过对比不同的查询结果来获取**个体**的私人隐私。注意我们希望保护的是**特定的某个个体**的隐私，也就是说，对于任何的个体，他的隐私都不被泄露。

## 差分隐私机制


为了解决隐私泄露的问题，差分隐私的概念由Dwork等人提出。从直觉上介绍，一个差分隐私机制掌控有一个数据库，接收用户的查询要求，根据要求返回一个统计数值。比如可以是这个数据库里带有某个性质的人的人数。 但返回精确的数值必定会导致隐私泄露，所以在差分隐私机制中我们引入随机性，使得每次机制返回的值不相同，但大致保持一定的准确度，从而达到隐私保护的作用。  

回到第一部分最后一个例子中，假如对于攻击者的第一次询问的回答是：198。那么攻击者会这样想：大概有200个人年收入在35万以上。假如对于攻击者第二次询问的回答是：201。同样地，攻击者得到的结论是：大概有200个人年收入在35万以上。这样一来，他就没有办法进行差分攻击来获得某个个体的隐私信息。  

具体地说，差分隐私要求对于分析者（或以上的攻击者）的提问，根据数据库$A$概率性地输出一个结果，这个结果在基于数据库包含某个用户$i$的情况和不包含$i$的情况下是相似的。 等价地说，假如有两个数据库 $A$ 和 $A^\prime$ ，其中$A$包含$i$的信息，$A^\prime$不包含$i$的信息，那么我们的差分隐私机制接收提问者的问题，然后分别基于这两个数据库的所输出的结果是大致相似的。更通俗地说，特定的某个$i$在不在分析考虑范围内对差分隐私机制所输出的结果影响不大。接下来我们严格的定义这一概念。

## 定义
我们定义数据集 $D$ 和 $D^\prime$为相邻数据集如果它们的对称差的大小为1， 即 $\mid D\Delta D\mid =1$。  

我们设随机算法为 $M$，数据分析者的查询函数空间为 $Q$，$M$的输出空间为$Y$。我们说 $M$ 是 $\epsilon-$差分隐私的，如果对于任意两个相邻数据集 $D$ 和 $D^\prime$，查询函数$q\in Q$，以及 $Y$ 的子集 $S$，我们说 $M$ 是 $\epsilon-$差分隐私的，$M$ 满足  

$$Pr[M(D)\in S]\leq e^\epsilon\cdot Pr[M(D^\prime)\in S]$$


## 参考文献

[1] Narayanan, Arvind, and Vitaly Shmatikov. “Robust de-anonymization of large sparse datasets.” Security and Privacy, 2008. SP 2008. IEEE Symposium on. IEEE, 2008.