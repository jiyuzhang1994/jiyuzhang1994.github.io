I"·<p>I‚Äôm reposting this to clearify questions I had when study these notes. I‚Äôll be using the conventional notations in [1].</p>

<p>There are two properties that Interactive Proofs must satisfy. Informally, a good interactive proof system for a language $L$ consists of a pair of prover and verifier $(P, V)$ that satisfies the following:</p>

<ol>
  <li>if $x\in L$, then there is a very large probability that $V$ accepts. (the <strong>completeness</strong>)</li>
  <li>if $x\not\in L$, then a malicious prover has very tiny chance to convince $V$ that $x\in L$. ( the <strong>soundness</strong>)</li>
</ol>

<p>Note that, in completeness, we consider both honest prover and honest verifier. The honest prover may be either computationally bounded or computationally unrestricted depending on the model we concern. In soundness, we consider malicious prover who can arbitrarily deviate from the protocol, and is computationally unrestricted. The verifier is considered to be honest in this case.</p>

<p>Zero knowledge proofs are, interactive proofs with an additional property called the zero knowledge property. The property says that in the interaction the prover doesn‚Äôt convey any knowledge but that the statement is true. In order to achieve this, we need to carefully define what is ‚Äúknowledge‚Äù.</p>

<p>As [1] suggests, ‚ÄúA conversation therefore conveys knowledge when the conversation allows the recipient to complete a ‚Äúnew‚Äù task that the recipient could not complete before‚Äù.</p>

<p>In the computational world, ‚ÄúThe amount of knowledge conveyed in a message can be quantified by considering the running time and size of a Turing machine that generates the message‚Äù. Therefore, the zero knowledge can mean that what you see doesn‚Äôt give you extra power to compute something. That is, the verifier can‚Äôt compute anything new given the messages communicated between the two parties.</p>

<p>It turns out that this (zero knowledge) is modeled by showing that, for any adversarial p.p.t. verifier <script type="math/tex">V^*</script> who tries to extract knowledge from the interaction, there exists a p.p.t. simulator <script type="math/tex">S^*</script> such that the following distributions are computationally indistinguishable:</p>

<ol>
  <li>$View[P(x) \leftrightarrow V^*(x)]$</li>
  <li>$S^*(x)$</li>
</ol>

<p>Informally, <strong>whatever Alice learns in the process can be produced by herself</strong>. So Alice can essentially simulate the interaction independently.</p>

<p>The following are some important notes I‚Äôd like to make.</p>

<h2 id="requiring-s-to-ouputcompute-vs-randomness">Requiring <script type="math/tex">S^*</script> to ouput/compute <script type="math/tex">V^*</script>‚Äôs randomness</h2>

<p>One thing [1] doesn‚Äôt specify is that the simulator necessarily needs to output the randomness the verifier is using. This is justified in [2] by giving an example of an interactive proof for graph isomorphism. The example shows the following:</p>

<ol>
  <li>
    <p>the protocol enables the verifier to learn the isomorphism (the witness) the prover holds.</p>
  </li>
  <li>
    <p>there exists a perfect simulator if we don‚Äôt require the simulator to output the randomness of the verifier.</p>
  </li>
</ol>

<p>Readers should refer to page 7-6 of [2] to see the example. We only explained what properties the protocol has.</p>

<h2 id="the-power-of-simulator">The power of simulator</h2>

<p>Another question we might have is: since a language equiped with a zk proof has a simulator, then it should be possible for a malicious prover to utilize this simulator to cheat the verifier, which seems to immediately contradict the soundness. The answer is that, the simulator is usually allowed to do more than what the prover can do. Specifically, the simulator can <strong>rewind</strong> the verifier.</p>

<p>Rewinding means that the simulator may essentially query the verifier from any previous internal states of it. In contrast, the real prover is defined not to be able to do this. <strong><em>What we can ask</em></strong> is why this model is of interest. An example is that you can consider the situation when you (a real prover) are entering a system and you‚Äôre asked to answer a sequence of questions. If in some steps you say:‚ÄùI want to go back to one of the previous questions, forget what I said just now.‚Äù Then this immediately causes the doubt of the verifier and it may simply halt and reject it.</p>

<p>To remark, the simulator lives in the same world as the verifier does. They have the same auxiliary input. The simulator can rewind the verifier, and can be quantum if the verifier is quantum.</p>

<p>Some remarks that might be helpful for understanding can be found at page 18 of [3]</p>

<p><strong>References</strong><br />
[1] R.Pass &amp; A.Shelat. A Course in Cryptography.<br />
[2] Rafail Ostrovsky. Foundations of Cryptography Draft Lecture Notes.<br />
[3] Yehuda Lindell. How To Simulate It ‚Äì A Tutorial on the Simulation Proof Technique. https://eprint.iacr.org/2016/046.pdf</p>
:ET