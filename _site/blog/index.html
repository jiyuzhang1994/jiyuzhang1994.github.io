<!DOCTYPE html>
<html lang="en-us">

  <head>
  <link href="https://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">

  <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <title>
    
      Blog &middot; Jiyu Zhang
    
  </title>

  <!-- CSS -->
  <link rel="stylesheet" href="/public/css/poole.css">
  <link rel="stylesheet" href="/public/css/syntax.css">
  <link rel="stylesheet" href="/public/css/hyde.css">
  <link rel="stylesheet" href="http://fonts.googleapis.com/css?family=PT+Sans:400,400italic,700|Abril+Fatface">

  <!-- Icons -->
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/public/apple-touch-icon-144-precomposed.png">
                                 <link rel="shortcut icon" href="/public/favicon.ico">

  <!-- RSS -->
  <link rel="alternate" type="application/rss+xml" title="RSS" href="/atom.xml">

  <script type="text/x-mathjax-config"> MathJax.Hub.Config({ TeX: { equationNumbers: { autoNumber: "all" } } }); </script>
   <script type="text/x-mathjax-config">
     MathJax.Hub.Config({
       tex2jax: {
         inlineMath: [ ['$','$'], ["\\(","\\)"] ],
         processEscapes: true
       }
     });
   </script>
    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
</head>


  <body class="theme-base-0d">

    <div class="sidebar">
  <div class="container sidebar-sticky">
    <div class="sidebar-about">
      <h1>
        <a href="/">
          Jiyu Zhang
        </a>
      </h1>
      <p class="lead">Contact: <br /> zjy9462 at gmail dot com</p>
    </div>

    <nav class="sidebar-nav">
      <a class="sidebar-nav-item active" href="/">About Me</a>
      <a class="sidebar-nav-item" href="/blog/">Blog</a>
      <a class="sidebar-nav-item" href="/Notes/">Notes</a>
      <a class="sidebar-nav-item" href="/Links/">Links</a>
    </nav>

    <p>&copy; 2019. All rights reserved.</p>
  </div>
</div>


    <div class="content container">
      <div class="posts">
  
  <div class="post">
    <h1 class="post-title">
      <a href="/CryptoLec02/">
        Intro to Cryptography 02:One Way Functions
      </a>
    </h1>

    <span class="post-date">30 Oct 2019</span>
    
      <p>In this note we mainly discuss common cryptographic primitives: one-way functions (OWF), one-way permutations (OWP) and trapdoor functions (TDP).</p>

    
  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/CryptoLec01/">
        Intro to Cryptography 01
      </a>
    </h1>

    <span class="post-date">29 Oct 2019</span>
    
      <p>I’m starting to study cryptography and would like to make some summary notes. I’ll mainly follow Yevgeniy Dodis’ notes at this <a href="https://cs.nyu.edu/courses/fall08/G22.3210-001/index.html">link</a>. Additionally, I also refer to other great notes such as [1][2][3] to cover additional discussions.</p>

<p>These notes will mostly focus on proofs and discussion on definitions and other details for the purpose of better understanding. Proofs are often based on the original notes, but I try to present in some equivalent ways as exercise. In some situations I also construct some proofs to complete originally omitted parts.</p>

<h2 id="1-the-basic-scenario-in-cryptography">1. The Basic Scenario in Cryptography</h2>

<p>The scenario involves three agents, Alice, Bob and Eve. Alice and Bob want to chat on a channel by sending messages to each other. Moreover, they would like to do this secretly so that only they know the (even partial) contents. In the basic model, Eve is the adversary who can observe whatever texts that are sent on the channel. Therefore Alice and Bob would like to encrypt their messages $m$ into a ciphertext $c$ that (as a goal) only they can decrypt. The goal of Eve is to infer the contents of $m$ based on $c$. WLOG, we assume Bob is the sender and Alice is the receiver. We name Bob’s encryption function as $Enc:$ $Enc(m, ???) \rightarrow c$ and Alice’s decryption function as $Dec:$ $Dec(c, ???) \rightarrow m$. The pair $(Enc, Dec)$ constitutes the communication scheme they use.</p>

<p>Initial assumptions we made are:</p>

<ul>
  <li>The encryption and decryption functions (algorithms) are known by all agents (in particular, Eve).</li>
  <li>Alice must always be able to recover $m$ (deterministially).</li>
  <li>Eve has unbounded computational power.</li>
</ul>

<h2 id="2-the-necessity-of-secret">2. The Necessity of Secret</h2>

<p>Base on the initial assumption, Do Alice and Bob necessarily need secret in order to achieve their private communication? The answer is yes, the following arguments establish the necessity.</p>

<ol>
  <li>
    <p><strong>Alice must have a secret from Eve.</strong><br />
If Alice doesn’t have a secret, then Alice should be no different from Eve, while by assumption Eve is even computationally stronger than Alice (Eve has unbounded computationl power). Therefore what Alice can do can also be done by Eve, the communication scheme must fail.</p>
  </li>
  <li>
    <p><strong>Bob must have a secret from Eve. In fact, Alice and Bob must share a secret $s$ not known to Eve.</strong><br />
Suppose Bob doesn’t have a secret, since Eve has unbounded computational power, she can iterate (try) all the message $m$ and other information $X$ used by Bob to produce $c$, which is the ciphertext sent by Bob. She can claim that the message $m$ she had tried so that $Enc(m, X)\rightarrow c$ is exactly the message sent by Bob. Why? <br />
The reason is that, if otherwise there is a different $m^{\prime} \neq m$ such that $Enc(m^\prime, X^\prime)=c$, (Here $X^\prime$ is not necessarily different from $X$, as long as we have $(m, X) \neq (m^\prime, X)$) then how can Alice know which of $m$ and $m^\prime$ was sent by Bob? As we discussed above, Alice holds a secret $s$, which is a part of $m$ plus $X$ and enables her to differentiate $(m, X)$ and $(m^\prime, X^\prime)$. Also, Bob must know this secret in order to send his message (express his intention) correctly. On the other hand, Eve cannot distinguish $(m, X)$ and $(m, X^\prime)$ because of the lack of the secret key $s$.</p>
  </li>
</ol>

<h2 id="3-perfect-security">3. Perfect Security</h2>

<p>We formally define what we mean by a scheme is secure. Ideally, we want that the event Eve seeing the ciphertext $c$ does not increase her chance to guess the message $m$. We denote $M$ as the random variable of message, $C$ for ciphertext accordingly.</p>

<p><strong>Definition 3.1 (Perfect Security)</strong> We say a system is secure if for any message $m$, $c = Enc_s(m)$ where $s$ is chosen uniformly at random. <script type="math/tex">\Pr(M=m) = \Pr(M=m\mid C=c)</script></p>

<p>One-Time Pad (OTP) is a perfectly secure system.</p>

<p><strong>Definition 3.2 (One-Time Pad)</strong> One-Time Pad is the the system $(Enc, Dec)$ where $Enc$ gets $c$ by XOR a random key $s$ with message $m$ and $Dec$ decrypts by XOR the same key $s$ with $c$:</p>

<script type="math/tex; mode=display">Enc(m, s) = m\oplus s</script>

<script type="math/tex; mode=display">Dec(c, s) = c\oplus s</script>

<p><strong>Exercise.</strong> Prove that OTP is perfectly secure.</p>

<p><strong>Discussion.</strong> <strong>1.</strong> Although OTP is perfectly secure, as its name suggests, the same key mustn’t be used twice. Indeed if we XOR $m \oplus s$ and $m^\prime \oplus s$ we get $m \oplus m^\prime$. <strong>2.</strong> In fact the following theorem due to Shannon says that perfect security under our initial assumptions requires that the secret $s$ has at least the same length as message communicated, which is not practical.</p>

<p><strong>Theorem 3.1</strong>  (Shannon) For any perfectly secure system where Alice and Bob share a key $s$ from space $S$ assume messages $m$ are from space $M$, we must have $\mid S \mid \geq \mid M\mid$.</p>

<p><strong>Proof</strong> 
Fix any ciphertext $c$ and key $s$, since $Dec_s$ is deterministic, $c$  must be decrypted into at most message. Therefore, the number of possible one messages resulted from all $s\in S$, we denote by $A$, should satisfy $A\leq \mid S\mid$. On the other hand, we should have $A = \mid M\mid$. Otherwise for some $m$ $Pr[M=m \mid C=c] = 0$, which contradicts the perfect security.</p>

<h2 id="4-more-discussion">4. More Discussion</h2>
<p>In real world we may not want to assume Eve has unbounded computational power, because Eve is just a human being like us all! While Eve does have the ability to guess. We can now relax the assumption and assume Eve is in <em>Probabilistic Polynomial Time (PPT)</em>. This actually makes a big difference. Let’s re-examine the two necessity above.</p>

<ol>
  <li>
    <p><strong>Alice must have a secret from Eve.</strong><br />
Well this should still hold because the same reason as above.</p>
  </li>
  <li>
    <p><strong>Bob must have a secret from Eve. In fact, Alice and Bob must share a secret $s$ not known to Eve.</strong><br />
This may not hold as previous. Why? Because now Eve is bounded in PPT, she is not allowed to do the previous iterative method. For now I think this is intuitive, maybe we can see more formal arguments (proofs) in later notes.</p>
  </li>
</ol>

<p>In summary, two things might be improved from the relaxation of assumptions. First, Bob may not need a secret from Eve. Second, the length of secret key may be shorter than message length (overcoming shannon’s barrier).</p>

<h2 id="references">References</h2>

<p>[1] Rafail Ostrovsky. Foundation of Cryptography. http://web.cs.ucla.edu/~rafail/PUBLIC/OstrovskyDraftLecNotes2010.pdf<br />
[2] R. Pass and A. Shelat. A Course in Cryptography. http://www.cs.cornell.edu/courses/cs4830/2010fa/lecnotes.pdf<br />
[3] Shafi Goldwasser, Mihir Bellare. Lecture Notes on Cryptography. https://cseweb.ucsd.edu/~mihir/papers/gb.pdf</p>

    
  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/dpsurvey/">
        差分隐私 Differential Privacy
      </a>
    </h1>

    <span class="post-date">16 Oct 2019</span>
    
      <p>注：这篇文章的目的在于通过介绍问题背景与实例来使读者对差分隐私这一概念的建立直觉/初步的理解，并对它的数学定义进行讨论。由于时间关系，我们不对前沿的细节做深入的调研，只做简单地了解。</p>

<h2 id="一问题背景">一、问题背景</h2>

<p>在大数据时代，很多互联网公司将收集的用户使用信息或记录保存于数据库，并通过数据分析手段来提高用户的体验。 在这个过程中不可避免地就会出现隐私泄露的问题。数据集中可能包含有用户的医疗诊断信息，个人消费偏好等信息，个人的此类信息遭遇泄露的话，难免会被有心人利用并导致对个人不利的后果。</p>

<p>一个比较典型的隐私泄露事件发生在06年的时候，Netflix（美国一家媒体服务提供商） 发起了一个有100万美金奖励的数据挖掘竞赛。 他们发布了一组关于用户浏览记录的数据集， 如果有人能通过这份数据集使他们的推荐系统的效能提高10%就可获得奖金。 当然，为了保护用户隐私，他们声称已经把包含用户ID的信息都删除以实现匿名化。 问题在于，这样是否真的已经将用户的信息隐藏起来？答案是否定的。来自 UT Austin 的 Arvind Narayanan 和 Vitaly Shmatikov 的工作[1]通过把已公布的数据库与 Internet Movie Database (IMDb) 结合起来，实现了一定程度反匿名化，暴露了用户的信息。</p>

<p>可以举一个简单的例子来从直觉上解释怎么做到反匿名的过程: 假如有一个数据库 $A$，里面包含了一些用户的 性别，出生日期，邮政编码，或是在一段时间内看过某场电影，但没有姓名，身份证信息。而另外一个数据库 $B$ 里包含一些用户的姓名，性别，邮政编码，出生日期，医疗信息，住址。 这样，通过对比这两个公开的数据库（比如相同的邮编和出生日期），我们可以很容易地猜出 $B$ 中的哪些人对应 $A$ 中的哪些信息。这样的攻击我们称为<strong>链接攻击 (Linkage Attack)</strong>。</p>

<p>另外一个例子解释攻击者可以通过不同的询问方式来问出私人信息。攻击者第一次进行这样的提问：“在2001年，P大学的大一新生有多少人家庭年收入35万以上？” 他得到准确答案是200。他接着提问：“在2002年， P大学的大二学生有多少人家庭年收入在35万以上？” 这次他得到答案是199。 于是他通过另外一种方式得知一名叫张知秋的同学在大二时退学了（比如查询在校学生表格）。 这样他可以得出结论：张知秋同学的家庭年收入在35万以上。这样的攻击我们称为<strong>差分攻击 (Differencing Attack)</strong>。</p>

<p>差分隐私就是为了防止这样的攻击而提出，它的最终目的是使得数据分析者能对数据库进行<strong>隐私保护的数据分析(privacy-preserving data analysis)</strong>。在差分隐私机制中，我们希望通过对数据库返回的值进行一定的处理，从而使得返回结果具有一定的随机性，但大致保持一定的精确度。这样，就能防止攻击者通过对比不同的查询结果来获取<strong>个体</strong>的私人隐私。注意我们希望保护的是<strong>特定的某个个体</strong>的隐私，也就是说，对于任何的个体，他的隐私都不被泄露。</p>

<h2 id="二差分隐私机制">二、差分隐私机制</h2>

<p>为了解决隐私泄露的问题，差分隐私的概念由Dwork等人提出。从直觉上介绍，一个差分隐私机制掌控有一个数据库，接收用户的查询要求，根据要求返回一个统计数值。比如可以是这个数据库里带有某个性质的人的人数。 但返回精确的数值必定会导致隐私泄露，所以在差分隐私机制中我们引入随机性，使得每次机制返回的值不相同，但大致保持一定的准确度，从而达到隐私保护的作用。</p>

<p>回到第一部分最后一个例子中，假如对于攻击者的第一次询问的回答是：198。那么攻击者会有这样的结论：大概有200个人年收入在35万以上。假如对于攻击者第二次询问的回答是：201。同样地，攻击者得到的结论是：大概有200个人年收入在35万以上。这样一来，他就没有办法进行差分攻击来获得某个个体的隐私信息。</p>

<p>具体地说，差分隐私要求对于分析者（或以上的攻击者）的提问，根据数据库$A$概率性地输出一个结果，这个结果在基于数据库包含某个用户$i$的情况和不包含$i$的情况下是相似的。 等价地说，假如有两个数据库 $A$ 和 $A^\prime$ ，其中$A$包含$i$的信息，$A^\prime$不包含$i$的信息，那么我们的差分隐私机制接收提问者的问题，然后分别基于这两个数据库的所输出的结果是大致相似的。更通俗地说，特定的某个$i$在不在分析考虑范围内对差分隐私机制所输出的结果影响不大。接下来我们严格定义这一概念。</p>

<h2 id="三定义">三、定义</h2>
<p>我们定义数据集 $D$ 和 $D^\prime$ （$D,D^\prime\in \chi^n$， $\chi$为数据空间)为相邻数据集如果它们只在某一个位置不同。 如果它们在$k$个位置不同，我们称它们间的距离为$k$。</p>

<p><strong>定义</strong> 我们设随机算法为 $M$，数据分析者的查询函数空间为 $Q$，$M$的输出空间为$Y$。我们说 $M$ 是 <strong>$\epsilon-$差分隐私</strong>的，如果对于任意两个相邻数据集 $D$ 和 $D^\prime$，查询函数$q\in Q$，以及 $Y$ 的子集 $S$，$M$ 满足</p>

<script type="math/tex; mode=display">Pr[M(D)\in S]\leq e^\epsilon\cdot Pr[M(D^\prime)\in S]</script>

<p><strong>讨论</strong> 在定义两个输出相接近时，为什么不使用<em>统计距离（statistical distance）</em>？ 也就是说，为什么不使用定义 $SD \left( M(D),M(D^\prime)\right)&lt;\epsilon$？</p>

<p>我们分两种情况讨论使用统计距离的不合理性 —</p>
<ol>
  <li>设 $\epsilon&lt; \frac{1}{10n}$，那么对于原数据库 $D$ 以及任意不同的数据库 $D^\prime$（即使$D$与$D^\prime$之间的距离为$n$），$M(D)$ 与 $M(D^\prime)$ 的统计距离最多相差$n\cdot \frac{1}{10n}=\frac{1}{10}$。特别地，$M(D)$与$M(0^n)$的距离最多为$\frac{1}{10}$。 换句话说，基于任意两个数据集的分析结果差距都不大，那我们所收集的$D$的使用价值就不大。</li>
  <li>设$\epsilon\geq\frac{1}{10n}$。考虑以下机制：以$\frac{1}{10}$的概率随机输出数据库的某行信息。可以验证这样的机制满足我们的定义。但这样的机制是不被允许的 （暴露了输出的那个<strong>个体</strong>的信息）。</li>
</ol>

<h2 id="四一个差分隐私机制的例子">四、一个差分隐私机制的例子</h2>

<p>我们考虑计数查询函数<script type="math/tex">q\in Q:\chi^n \rightarrow \{0, 1\}</script> 并定义 $q(x) = \sum_i^{n} q(x_i)\ mod\ 2$， 考虑以下机制：</p>

<script type="math/tex; mode=display">M(x,q) = q(x) + Lap(1/\epsilon)</script>

<p>其中 $Lap(\lambda)$ 为拉普拉斯分布，其概率密度函数正比于$e^{-\mid y\mid /\lambda}$。我们证明$M$为<strong>$\epsilon-$差分隐私</strong>的。</p>

<p><strong>证明</strong></p>

<p>可以得到$[M(q,x)=y]$的概率密度函数正比于$e^{-\epsilon\mid y-q(x)\mid}$。 同样地，$[M(q,x^\prime)=y]$正比于$e^{-\epsilon\mid y-q(x^\prime)\mid}$。 由于$q(x)$与$q(x^\prime)$最多相差为1，因此将他们的概率密度函数相除，剩余因数大小为$e^\epsilon$，刚好满足$\epsilon-$差分隐私的要求。</p>

<h2 id="五总结讨论">五、总结讨论</h2>

<h3 id="缺点">缺点</h3>

<p>差分隐私的缺点在于加入随机性会使数据的可用性下降，所以在保护隐私的同时对数据分析的结果有一定的影响，在实际应用中要在这两个因素中做权衡。</p>

<h3 id="与计算复杂度">与计算复杂度</h3>

<p>对如今大部分的差分隐私机制设计，我们都没有考虑复杂度假设。假如我们限制数据库的监护者（机制的设计者）的计算能力（比如多项式时间的计算能力），这样会使差分隐私的实现难度变大。特别地，在[3]中的第9章Dwork&amp;Roth给出了在存在复杂度假设的情况下，根据某一些计数查询函数，不能高效地生成有用的数据库的例子，有兴趣可进行查阅。</p>

<h3 id="工业界应用情况">工业界应用情况</h3>

<p>近期已经有一些业界企业将差分隐私应用于他们的业务中，比如Apple已经将差分隐私的技术用于使用机器学习改善用户体验的过程，具体报告可见此<a href="https://machinelearning.apple.com/2017/12/06/learning-with-privacy-at-scale.html">链接</a>。 另外，谷歌最近也有做此类尝试，<a href="https://arxiv.org/abs/1905.02249">链接</a>。</p>

<h2 id="参考文献">参考文献</h2>

<p>[1] Narayanan, Arvind, and Vitaly Shmatikov. “Robust de-anonymization of large sparse datasets.” Security and Privacy, 2008. SP 2008. IEEE Symposium on. IEEE, 2008.<br />
[2] Dwork “Differential Privacy: A Survey of Results”. https://web.cs.ucdavis.edu/~franklin/ecs289/2010/dwork_2008.pdf<br />
[3] Dwork and Roth “The Algorithmic Foundations
of Differential Privacy”. https://www.cis.upenn.edu/~aaroth/Papers/privacybook.pdf<br />
[4] Vadhan “The Complexity of Differential Privacy” http://privacytools.seas.harvard.edu/files/privacytools/files/complexityprivacy_1.pdf</p>

    
  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/glthm/">
        Goldreich Levin Theorem
      </a>
    </h1>

    <span class="post-date">04 Oct 2019</span>
    
      <p>In this blog we study and present the proof of Goldreich-Levin theorem. The main material we use is the  course notes of Prof. Luca Trevisan (see references at the end).</p>

<p>The Goldreich-Levin Theorem has several interpretations. We will first explain and prove it from cryptographic view. Then we will see in fact it can also be viewed as list-decoding of Hadamard code.</p>

<h2 id="background">Background</h2>
<p>In this section we present necessary definitions and math inequalities we will be using. The first theorem is a variant of Markov inequality.</p>

<p><strong>Theorem 1 (Markov Inequality, Variant)</strong> Suppose $X$ is a random variable in $[0, 1]$ and $0&lt;t&lt;E[X]$, then</p>

<script type="math/tex; mode=display">Pr[X\geq t] \geq \frac{E[X]-t}{1-t}</script>

<p><strong>Proof:</strong></p>

<p>Let $S$ denote the set of $x$ such that $X(x)\geq t$, then</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align*} 
E[X] &= \sum_{x\in S}Pr(x)X(x) + \sum_{x\not\in S}Pr(x)X(x)\\ 
 &\leq \sum_{x\in S}Pr(x)\cdot 1 + \sum_{x\not\in S}Pr(x)\cdot t\\
 &= Pr(S) + t\cdot (1-Pr(S))\\
 &= (1-t)\cdot Pr(S) + t
\end{align*} %]]></script>

<p><strong>Theorem 2 (Chernoff Bound)</strong>  Suppose $X_1, \ldots, X_k$ are $0, 1$ <em>i.i.d</em> random variables and $ X = \sum_i^{k} X_i$, then for any $0&lt;\epsilon&lt;1$:</p>

<script type="math/tex; mode=display">% <![CDATA[
Pr[\ X>(1+\epsilon)E[X]\ ]<e^{-\frac{\epsilon^2}{3}\cdot E[X]} %]]></script>

<script type="math/tex; mode=display">% <![CDATA[
Pr[\ X<(1-\epsilon)E[X]\ ]<e^{-\frac{\epsilon^2}{3}\cdot E[X]} %]]></script>

<p><strong>Theorem 3 (Chebyshev Inequality)</strong><br />
Suppose $X= X_1 + \cdots + X_k$ where $X_1, \ldots ,X_k$ are $0, 1$ pairwise independent variables and $t&gt;0$, then</p>

<script type="math/tex; mode=display">Pr[\mid X-E[X]\mid \geq t] \leq \frac{Var(X_1) + \cdots + Var(X_k)}{t^2}</script>

<p>In particular, if for each $X_i$, $Pr[X_i = 1] \geq 1/2 + \epsilon$, then $Var(X_i)&lt;\frac{1}{4}$, therefore</p>

<script type="math/tex; mode=display">Pr[\mid X-E[X]\mid \geq t] \leq \frac{Var(X_1) + \cdots + Var(X_k)}{t^2}\leq \frac{k}{4t^2}</script>

<p><strong>Proof</strong></p>

<p>Let $S$ be the set of $x$ such that $\mid X(x)-E[X]\mid \geq t$</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align*} 
Var[X] &= \sum_x (X(x)-E[X])^2 \cdot Pr(x)\\
 &= \sum_{x\in S}(X(x)-E[X])^2 \cdot Pr(x) + \sum_{x\not\in S}(X(x)-E[X])^2 \cdot Pr(x)\\
 &\geq Pr(S)\cdot t^2 + 0
\end{align*} %]]></script>

<p>So</p>

<script type="math/tex; mode=display">Pr(S) \leq \frac{Var[X]}{t^2}</script>

<p>and</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align*} 
Var[X_1+X_2] &= E[(X_1+X_2)^2] - E(X_1+X_2)^2\\
&= E[X_1^2] + 2E[X_1X_2] + E[X_2]^2 - E[X_1]^2 -2E[X_1]E[X_2] - E[X_2]^2\\
&= Var[X_1]+Var[X_2]
\end{align*} %]]></script>

<p>this can be easily generalized to show $Var[X_1 + \cdots + X_k]= Var[X_1] + \cdots + Var[X_k]$</p>

<p><strong>Definition 1 (Hard-Core Predicate)</strong> A boolean function <script type="math/tex">P: \{0, 1 \}^n \rightarrow \{0, 1\}</script> is $(t, \epsilon)$ - hard core for a permutation <script type="math/tex">f: \{0,1\}^n \rightarrow \{0,1\}^n</script> if for every algorithm $A$ of complexity $t$</p>

<script type="math/tex; mode=display">\Pr_{x\sim \{0, 1\}^n}[A(f(x)) = P(x)]\leq \frac{1}{2}+\epsilon</script>

<p>Note: we use <script type="math/tex">x\sim \{0, 1\}^n</script> to denote uniform distribution over <script type="math/tex">\{0, 1\}^n</script></p>

<h2 id="goldreich-levin-theorem">Goldreich-Levin Theorem</h2>

<p>We denote inner product modulo 2 using the following notation:</p>

<script type="math/tex; mode=display">\langle x,r\rangle = \sum_i x_i\cdot r_i\ mod\ 2</script>

<p>The Goldreich-Levin theorem says that a random XOR is hard-core for every one-way permutation. This means that if there is an efficient algorithm to predict $\langle x, r\rangle$, given $f(x)$ and $r$, then there is also an efficient algorithm to compute a pre-image of $f(x)$, so if $f(x)$ is a one-way function, we can invert it with noticeable probability.</p>

<p><strong>Theorem 1 (Goldreich-Levin Theorem)</strong> <em>Suppose $A$ is an algorithm of complexity $t$ such that</em></p>

<script type="math/tex; mode=display">\Pr_{x, r} [A(f(x),r)\ =\ \langle x ,r\rangle] \geq \frac{1}{2} + \epsilon</script>

<p><em>Then there is an algorithm $A^\prime$ of complexity at most $O(t\epsilon^{-2}n^{O(1)})$ such that</em></p>

<script type="math/tex; mode=display">\Pr_x[A^\prime(f(x)) = x] \geq \Omega(\epsilon)</script>

<p>We will first prove a weak Goldreich-Levin algorithm, which will later be used in our proof of GL theorem.</p>

<p><strong>Theorem 2 (Goldreich-Levin Algorithm Weak Version)</strong> <em>Suppose there is a function $H$ such that, for some $x$</em></p>

<script type="math/tex; mode=display">\Pr_r[H(r)\ =\ \langle x,r\rangle]\ \geq \frac{3}{4} + \epsilon</script>

<p><em>Then there is an algorithm $GLW$ that can output $x$ with high probability ( $\geq 1-\frac{1}{n}$ ).</em></p>

<p>Let’s first see how an easy algorithm can find $x$ when the probability on the right side is 1 in the above (so that $H(r)$ outputs $\langle x,r\rangle$ correctly).</p>

<p>Let $e_i$ denote the vector in which the $i$th bit is 1 and 0 otherwise. $x_i = H(e_i) = \langle x, e_i \rangle$. Then we can output $x$ by enumerating all the $e_i$.</p>

<p>Now to prove Theorem 2, note that $H(r)$ fails with small probability, we’ll use the majority vote method. Intuitively,  we randomly sample several points $r_1 \ldots r_k$. Let $H^\prime_{r_1 \ldots r_k}(e_i)$ be the function that take the majority of  $H(r_j+e_i) - H(r_j)$ on these $r_j$s. The observation is that if $H(r)$ computes $\langle x, r\rangle$ correctly, then we have:</p>

<script type="math/tex; mode=display">\langle x, r_j+e_i \rangle - \langle x, r_j \rangle = \langle x, e_i\rangle</script>

<p>We now bound the probability that $H(r_j + e_i) - H(r_j)$ fails.</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align*}
  Pr[H(r_j + e_i) - H(r_i) \neq  \langle x, e_i\rangle] &= Pr[H(r_j + e_i) \neq \langle x, r_j+e_i \rangle\ \cup H(r_j) \neq \langle x, r_j \rangle]\\
  &\leq Pr[H(r_j + e_i) \neq \langle x, r_j+e_i \rangle]\ + Pr[H(r_j) \neq \langle x, r_j \rangle]\\
  &\leq \frac{1}{4} - \epsilon + \frac{1}{4} - \epsilon\\
  &\leq \frac{1}{2} - 2\epsilon
 \end{align*} %]]></script>

<p>The GLW algorithm is as follows:</p>

<ul>
  <li>GLW Algorithm:</li>
  <li>for $i= 1, 2, \ldots , n$:
    <ul>
      <li>for $j = 1, 2, \ldots , 4\log n/ \epsilon^2$:
        <ul>
          <li>randomly sample <script type="math/tex">r_j\in \{0, 1\}^n</script></li>
          <li>compute $H(r_j + e_i) - H(r_j)$</li>
        </ul>
      </li>
      <li>compute <script type="math/tex">x_i = H^\prime_{r_1 \ldots r_k}(e_i) = Majority\{H(r_j + e_i) - H(r_j): j = 1, 2, \ldots , 4\log n/ \epsilon^2 \}</script></li>
    </ul>
  </li>
  <li>return $x$</li>
</ul>

<p>Now we analyze this algorithm. Since each $H(r_j + e_i) - H(r_j)$ outputs the correct answer with probability at least $1/2 + 2\epsilon$. By the Chernoff Bound (Theorem 2 in Background), the probability that the majority function $H^\prime_{r_1 \ldots r_k}(e_i)$ fails to output $x_i$ is at most $e^{-2\log n} = O(\frac{1}{n^2})$. Then the union bound gives us that GLW outputs $x$ correctly with probability at least $1-1/n$. The algorithm runs in time $O(\frac{n^2 \log n}{\epsilon^2})$, makes $O(\frac{n\log n}{\epsilon^2})$ queries to $H$.</p>

<p><strong>Discussion.</strong> The above framework only works for cases where $\Pr_r[H(r) = \langle x, r \rangle]$ greater than $\frac{3}{4}$. For the case in Goldreich-Levin theorem where $H(r)$ makes more error,the union bound gives probability less than $1/2$ and the Chernoff Bound won’t work. In fact, it is possible to construct a function $H$ such that $Pr[H(r) = \langle x, r\rangle] = 3/4$ and $Pr[H(r) = \langle x^\prime, r\rangle] = 3/4$ where $x \neq x^\prime$. So no algorithm can guarantee to find the correct $x$ when given such $H$, since $x$ is not uniquely defined by $H$. However, the Goldreich-Levin theorem tells us how to find a list of possible candidates of $x$ with good probability. We present their algorithm below.</p>

<p>We proceed to prove the Goldreich-Levin Theorem.</p>

<p>Given (as in the Goldreich-Levin theorem) $\Pr_{x, r} [A(f(x),r)\ =\ \langle x ,r\rangle] \geq \frac{1}{2} + \epsilon$, we first show that there is a certain fraction of $x$,  $\Pr_r[A(f(x), r) = \langle x, r \rangle] \geq \frac{1}{2} + \frac{1}{2}\epsilon$ holds, and we call such $x$ “good” :</p>

<p><script type="math/tex">\Pr_{x, r} [A(f(x),r)\ =\ \langle x ,r\rangle]</script> can be viewed as <script type="math/tex">\sum_x Pr(x)\Pr_r[A(f(x),r)\ =\ \langle x ,r\rangle]</script>,  which is equal to the expectation <script type="math/tex">E_x[\ \Pr_r[A(f(x),r)\ =\ \langle x ,r\rangle]\ ]</script> ( so we view <script type="math/tex">\Pr_r[A(f(x),r)\ =\ \langle x ,r\rangle]</script> as a random variable of $x$). Now we have the expectation is greater than $1/2 + \epsilon$, by the Markov ineuality (Theorem 1 in background) we have:</p>

<script type="math/tex; mode=display">\Pr_x \left[\ \Pr[A(f(x),r)\ =\ \langle x ,r\rangle ]\geq \frac{1}{2} + \frac{1}{2}\epsilon\ \right]\geq \frac{\frac{1}{2}\epsilon}{\frac{1}{2}-\frac{1}{2}\epsilon}\geq \frac{\epsilon}{2}</script>

<p>So at least $\frac{\epsilon}{2}$ of $x$ are good. On these good $x$, we prove the GL algorithm:</p>

<p><strong>Theorem 3 (Goldreich-Levin Algorithm)</strong>
<em>Suppose there is a function $H$ such that, for some $x$:</em></p>

<script type="math/tex; mode=display">\Pr_r[H(r) = \langle x, r \rangle] \geq \frac{1}{2} + \epsilon</script>

<p><em>Then there is an algorithm GL outputs a list $L$ of candidates of $x$, such that $L$ is of size $O(\epsilon^{-2})$ and $x\in L$ with probability  at least $1/2$. The GL algorithm runs in time $O(n^2 \epsilon^{-4} \log n)$, makes $O(n\epsilon^{-4}\log n)$ queries to $H$.</em></p>

<p>As discussed above, we now don’t have $H(r)$ that predicts $\langle x, r \rangle$ well, so $H(r+r_j) - H(r_j)$ fails to predict $\langle x, r \rangle$ with high probability ($ &gt; 1/2$). However, let’s make an assumption that, instead of $H(r_j)$, we get the correct $\langle x, r_j \rangle$ for every $j$, so now $H(r+r_j) - \langle x, r_j \rangle$ succeeds with probability at least $1/2 + \epsilon$. We do an error reduction by taking $k= O(\frac{1}{\epsilon^2})$ samples of $r_j$, then apply the majority vote method. Thus we can reduce the probability to match that in Theorem 2 and apply the GLW algorithm to find $x$.   <br />
Moreover, since we dont’ know the correct $\langle x, r_j \rangle$, we just enumerate all the possible values of it, which gives the following (inefficient) algorithm:</p>

<ul>
  <li>Inefficient GL algorithm:</li>
  <li>randomly sample <script type="math/tex">r_1, \ldots, r_k \in \{0, 1\}^n</script> where $k =  O(\frac{1}{\epsilon^2})$</li>
  <li>for <script type="math/tex">b_1, \ldots, b_k \in \{0, 1\}</script> (each $b_j$ corresponds to a possible value of $\langle x, r_j \rangle$) :
    <ul>
      <li>let <script type="math/tex">H^\prime_{r_1 \ldots r_k}(r) :=  Majority\{H(r_j + r) - b_j: j = 1, 2, \ldots, k \}</script></li>
      <li>run GLW algorithm in Theorem 2, using $H^\prime_{r_1 \ldots r_k}(r)$ instead of $H(r)$, outputs $x$</li>
      <li>add $x$ to list $L$</li>
    </ul>
  </li>
  <li>return $L$</li>
</ul>

<p><em>Analysis:</em>  By the Chernoff Bound we have, on the correct $b_j$’s,</p>

<script type="math/tex; mode=display">\Pr_{r,r_1,\ldots, r_k}[H^\prime_{r_1 \ldots r_k}(r) = \langle x, r\rangle]\geq 1-o(1)\geq 1-\frac{1}{32}</script>

<p>It follow by the Markov Inequality that</p>

<script type="math/tex; mode=display">\Pr_{r_1, \ldots, r_k}[\Pr_r[H^\prime_{r_1 \ldots r_k}(r) = \langle x, r\rangle] > \frac{3}{4}]> \frac{31}{32}</script>

<p>By the GLW algorithm, with probability at least $\frac{31}{32} - \frac{1}{n} &gt; \frac{1}{2}$, $x$ is in the list.</p>

<p><strong>Discussion.</strong> The above algorithm is inefficient in that the size of $L$ is $2^k$, which is exponential in $k$, the GL algorithm below reduces this using pairwise independence.</p>

<ul>
  <li>GL algorithm:</li>
  <li>Randomly sample <script type="math/tex">r_1, \ldots, r_k \in \{0, 1\}^n</script> where $k =  O(\log \frac{1}{\epsilon^2})$</li>
  <li>for each subset <script type="math/tex">S\subseteq \{r_1, \ldots, r_k\}</script>, define $r_S = \sum_{i\in S} r_i$</li>
  <li>for all <script type="math/tex">b_1 \ldots, b_k \in \{0, 1\}</script>:
    <ul>
      <li>define $b_S = \sum_{i\in S} b_i$</li>
      <li>define <script type="math/tex">H^\prime(r) :=  Majority\{H(r_S + r) - b_S: S\subseteq \{r_1, \ldots, r_k\} \}</script></li>
      <li>run GLW algorithm in Theorem 2, using $H^\prime(r)$ instead of $H(r)$, outputs $x$</li>
      <li>add $x$ to list $L$</li>
    </ul>
  </li>
  <li>return $L$</li>
</ul>

<p>Now we analyze this GL algorithm. Since $r_1, \ldots, r_k$ are randomly picked, for any two different sets $S$ and $T$, $r_S$ and $r_T$ are pairwise independent, therefore $H(r_S+r) - b_S$ and $H(r_T+r) - b_T$ are pairwise independent. In addition, on the correct $b_S$, $H(r_S+r) - b_S = \langle x, r \rangle$ with probability at least $1/2 + \epsilon$. By the Chebyshev Ineuqality (Theorem 3 in background), $H^\prime(r)$ outputs the wrong value with probability at most $\frac{1}{4\epsilon^2 \cdot 2^{k}}$ where $k=O(\log \frac{8}{\epsilon^2})$, so the probability is at most $\frac{1}{32}$. Given such $H^\prime(r)$ the GLW algorithm will work well. <br />
The running time of GL algorithm is $O(n^2 \log n \cdot \epsilon^{-4})$, it makes$O(n^2\log n\cdot \epsilon^{-4})$ queries to $H$ and outputs a list $L$ of size $O(\frac{1}{\epsilon^2})$. $x$ is in $L$ with probability greater than $1/2$.</p>

<p><strong>Finalizing the proof.</strong> Since we have at least $\epsilon/2$ fraction of good $x$, combinging this with the GL algorithm we can conclude that with probability at least $\epsilon /4$ $x$ is in the list $L$. We can check $x$ by evaluating $f(x)$ to see if it equals our input $y$.</p>

<h2 id="references">References</h2>
<p>Lecture Notes 11, 12 of Luca Trevisan’s Spring 2009 Cryptography Courses, see this <a href="https://people.eecs.berkeley.edu/~luca/cs276/#notes">Link</a>.</p>

    
  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/ProofOfUndo/">
        Argument of Correctness of Undo Implementation
      </a>
    </h1>

    <span class="post-date">12 Aug 2019</span>
    
      <p>Recently I’ve implemented a simple project of text editor = =. One part of this project is to implement the undo functionality. In case the recuiter might be interested, I’d like to provide a proof here that my idea of implementation can correctly recover deleted characters in its original position, the potential problematic case won’t happen.</p>

<h2 id="introduction">Introduction</h2>
<p>Undo is the operation that can undo the user’s last $n$ operation(inserting/deleting characters).</p>

<p>The difficulty lies in how can one keep track of the original position of the characters deleted. Well, in my implementation, nothing else is needed: just remove the node(which contains a character) and put it into a stack.</p>

<p>The data strucutre I used for text editor is a doubly linked list, each node has a value contains the specific character, and a <strong>prev</strong> pointer to the previous character node and a <strong>next</strong> pointer to the next character node. Visualized as following:</p>

<div>$$a\leftarrow s \rightarrow b$$  </div>

<p>To recover the deleted node $s$, simply find its (relative) position by referring to its previous or next node, then insert it in.  While one thing might be problematic: <strong>what if when (the deleted) $s$ is to recover, its previous nodes a or b are not in the data structure, i.e. a and b haven’t been recovered</strong>. Therefore we can’t find its position. While I argue that this will not happen.</p>

<h2 id="the-argument">The Argument</h2>
<p>I’d like to show the following: <strong>when $s$ is to recover, its previous or next nodes must exist in the data structure</strong>, which is a simple argument by contradiction:<br />
Suppose for the contradiction that $a$ and $b$ are not in the data structure, then $a$ and $b$ must be deleted before $s$ is deleted. However, in this case, by the time $s$ is deleted, its <strong>prev</strong> and <strong>next</strong> cannot be $a$ and $b$, which is a contradiction.</p>


    
  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/derandlogspace/">
        Derandomizing Log Space vs. Fooling Log Space
      </a>
    </h1>

    <span class="post-date">25 Jan 2019</span>
    
      <p>上周的ToC reading group上讲到了最近的一篇ITCS paper [CHLT18]，主要是讲怎么通过bound一类方程的second-level fourier tail， 构建对于那个function family的PRG(Pseudorandom Generator)。 特别地，通过这篇paper的一个猜想（conjecture），我们可以得到AC[$\oplus$]的PRG。 在meeting上，Michael就问了AC[$\oplus$]是不是在BPL里，原因是我们知道怎么构建对于BPL的PRG(而且并不optimal，且仅仅是nonuniformly），但我们好像不知道怎么去fool所有的log space 的计算（实际上应该是L/poly)，而AC[$\oplus$]看起来是不像是在BPL里面的。因为之前对pseudorandomness for space-bounded computation了解还比较少，于是我也就找了一些相关的笔记看，这次就主要是想写下derandomizing BPL 和 fooling log space的区别。</p>

<h2 id="fooling-log-space"><strong>Fooling log space</strong></h2>
<p>当我们说fooling log space的时候， 实际上是指fooling L/poly。首先我们来看看什么是L/poly。回想我们定义P/poly的一个目的是想用一个combinatorial model，也就是 circuits 来 non-uniformly 模拟多项式时间(polynomial time)内对于每个输入长度n有poly(n)长度的advice的图灵机。这个circuit有多项式长度的描述（polynomial size description），也就相当于是一个图灵机有了多项式长度的advice，所以才写作P/poly。那么类似地，我们想用一个有多项式长度的描述的 combinatorial model 来模拟 log space的图灵机的计算并把它记作L/poly。这次我们用的model是branching program。首先回忆一下 log space的图灵机是怎么运行的：我们有一个只读（read-only)的输入带（input tape)，还有一个可以读写（read-write）的只有log长度的工作带（work tape），和一个write-only的 output tape。对于一个长度为n的input，log space的图灵机可以在input tape 上来回读取输入，然后在 $\log n$ space的work tape上进行计算，最后在output tape上输出结果。能被这种图灵机计算的complexity class我们称之为 L。注意在这个计算过程中图灵机的每一步计算的格局（configuration)都可以由它的 1.读取头在input tape上的位置 2.work tape上的内容 3.读取头里的状态 这三个元素组成的triple表示。接下来我们定义 branching program 并展示它怎么模拟 log space 的图灵机的计算。</p>

<p>一个branching program是一个acyclic graph。在这个图里面每一个node都有个label是 $x_i$，表示input的第$i$个variable。这个图有一个start node和两个end node。每个node（除了end node）都有两个ouput edge，一个由1标注，一个由0标注：如果node的variable的值是1，就沿1的边走，如果是0，就沿0的边走。 两个end nodes一个由0标注一个由1标注。 有了这样的定义我们就可以描述一个长度为n的输入在这个model上是怎么计算的了：对于此长度为n的输入，我们从start node看起，如果node上标注的variable的值为1的话就沿标注1的边看下一个node，如果是0就沿标注0的边看下一个node，沿着这样的一条计算路径（path) 后最终会落到要么是0或是1的end nodes上。输出最后到达的end node的值。这个branching program的size就是这个图的node的数量。</p>

<p>要说明为什么一个polynomial size 的 branching program和L/poly 图灵机计算一样，试想我们上面说的一个configuration，是不是正好就和这个branching program里的一个node一样：node的标注（label）就是图灵机在input tape上的读取头的位置；我们一共有polynomial个nodes，正好对应work tape上的$2^{\log n}=poly(n)$种不同的binary string。这样就证明了poly-size branching program能计算L/poly。 另一个方向就仅仅是log space machine被给予这个branching program的description作为advice(which is poly-size)。</p>

<p>而Fooling L/poly 就是指我们要构造一个PRG G，使得对于任意的branching program B，$\mid{Pr[B(G(U_z))=1]-Pr[B(U_m)=1]}\mid &lt; \epsilon$。也就是说我们要把一个长度为z的truly random string，stretch成一个长度为 $\mid G(U_z)\mid=m$ 的 string $ G(U_z)$，使得所有的distinguisher B都不能区别它与长度为m的uniformly random string的区别。</p>

<h2 id="derandomizing-bpl"><strong>Derandomizing BPL</strong></h2>
<p>再来看BPL。同样地，fooling BPL 也是指fool一个non-uniform model。 Non-uniformly modeling BPL其实是用一个上述的branching program 的一个special case – Read-Once Branching Program(ROBP)。回想一下log space的 randomized computation，实际上就是在除input tape, work tape, output tape 外额外增加一个randomness tape。需要注意的是这个randomness tape是read once的，也就是说在运行的每一步我们依次读一个上面的random bit，并且这个bit是不能retrieve的。试想在randomized log space computation里面，我们也是在每一步投掷一次硬币（flip a coin），然后决定下一步做什么，而log space不足以储存这些random bits。这个计算过程恰好可以由ROBP模拟。</p>

<p>一个ROBP是一个acyclic layered graph。如下图所示，每层共有$2^S$个nodes，对应有S space的图灵机的 $2^S$个格局，每次从一层转移到下一层时，读取m个random bits，所以可以最多转移到2^m个configuration，即每个点有2^m个edge连接到下一层。在进行运算时，因为我们可以把input嵌入这个branching program中，所以可以每次只关心random bits。每读取m个ramdon bits，由一层转移到下一层，最后到达接受或拒绝的状态。</p>

<p><img src="/assets/ROBP.jpg" alt="" /></p>

<p>Derandomizing BPL就是指我们能构造一个PRG G，使得对于任意的ROBP $B^{\prime}$，$\mid{Pr[B^{\prime}(G(U_z))=1]-Pr[B^{\prime}(U_m)=1]}\mid &lt; \epsilon$。</p>

<p>由此可见，fooling log space 和 derandomizing BPL是不同的，前者需要fool 所有的 branching program，而后者只需要fool 一种特殊的 branching program – ROBP。前者难度比后者更大。</p>

<p><strong>References</strong><br />
[CHLT18]Eshan Chattopadhyay. Pooya Hatami. Shachar Lovett. Avishay Tal. Pseudorandom generators from the second Fourier level and applications to AC0 with parity gates</p>

<p>David Zuckerman. Lecture Notes of Pseudorandomness and Combinatorial Constructions (CS 395T), http://www.cs.utexas.edu/~diz/395T/01/</p>


    
  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/zkdefvar/">
        Zero-Knowledge Proofs:Definitions and Variants
      </a>
    </h1>

    <span class="post-date">04 Jan 2019</span>
    
      <p>Recently I’ve been reading some crypto papers. The concept of zero-knowledge proofs somehow interests me so I referred to some surveys and lecture notes to study this topic. I plan to write down some summaries within this topic, with an emphasis on the basic definition and its variants. <br />
最近在看一些密码学的论文，对其中<strong>零知识证明(zero-knowledge proofs)</strong>这个重要的概念很感兴趣，就把相关的笔记（notes）都看了一遍，打算把定义方面的理解以及变体的问题总结下来。</p>

<p>零知识证明是一种特殊的交互式证明方法（Interactive Proof）。我们知道，在交互式证明中， 我们要求证明或协议（Protocol）满足两个性质：完备性（Completeness）和 可靠性（Soundness），其中可靠性是为了防止恶意的（adversarial）证明者（Prover）。 一个恶意的证明者会想要欺骗验证者（Verifier）从而使验证者相信一个错误的命题，可靠性要求证明者只能有很小的概率能够欺骗验证者。而零知识证明在此之外增设了需满足的第三个性质–零知识性（Zero Knowledge）。不同于可靠性是为了针对恶意的证明者，零知识性是为了防止恶意的验证者获取一些他们想要的信息。</p>

<p>简单地说，零知识证明要求只保证验证者能确信命题的正确性， 除此以外，在证明过程中验证者不能获取其他任何的信息。比如说，在图同构问题（Graph Isomorphism）中，对于两个同构的图（G, H）这样的输入（a yes instance），零知识证明要求在交互证明结束后验证者 <strong>只能得出 “G和H确实是同构的”</strong> 这样一个结论，除此以外，他不能获取其他任何信息。比如说验证者不能得到一个排列（Permutation）- π， 使得对 G 的节点施加 π 后得到 H（i.e. π(G)=H）。</p>

<p>那么应该怎么合理地正式表达（Formulate）这样的要求呢？我们采用以下的方法来阐述这样的要求：任何验证者能从零知识证明过程中获取的信息，都能被与验证者有相同的计算能力的模拟者（Simulator）通过计算得到。模拟者（Simulator）在零知识证明中是一个很重要的概念，根据对模拟者的要求不同，会衍生出一些变体（variants）的定义，这点会在之后介绍。接下来要正式定义零知识：</p>

<p><strong>定义1.</strong>  对于一个协议 PV，我们用 View(PV(x)) 来表示在输入为x的情况下，按照 PV 来进行交互证明过程中，验证者视角所看到的信息。具体地说，View(PV(x)) 包含有：
1.整个证明过程中证明者P和验证者V之间来往的讯息
2.验证者V所使用的随机性（Randomness），或者说验证者的用来投掷并决定下一步的硬币（Coins）</p>

<p>此外，用 [View(PV(x))] 来表示 View(PV(x)) 在P和V所用的随机性下的概率分布（distribution）</p>

<p><strong>定义2.</strong>  对于一个语言 L，我们称一个交互式证明或协议 PV 是<strong>零知识</strong>的，如果</p>

<div>
$$\forall V^{\prime} \exists S\in PPT\ s.t\ \ \forall x\in L$$  
</div>
<div>
$$[View(S(x))]\simeq [View(PV^{\prime}(x))]$$
</div>

<p>也就是说，对于任何验证者，都存在一个模拟者（多项式时间的概率图灵机）使得对于（语言L内）任意的x作为输入时，模拟者与验证者所看到的变量的分布是（几乎）相同的。
更通俗地说， 对于任何验证者视角下交互证明过程中的变量的分布，该验证者都能自身生成（generate）这样的分布。</p>

<p>需要补充说明的是，上面定义里的量词是针对所有的 V’。特别地，PV’不一定是 L 的交互式证明或协议。也就是说，在上面的定义里，V’的目标只是想尽办法从证明者P那里获取有用的信息。而如果我们要求 PV’ 是一个 L 的交互式证明或协议，那么我们称之为<strong>诚实验证者零知识</strong>（Honest Verifier Zero Knowledge，i.e. HVZK）。</p>

<p>另一方面，根据分布的“相同”的不同定义，零知识性质也可分类为：<strong>完全零知识</strong>（Perfect Zero Knowledge），<strong>统计零知识</strong>（Statistical Zero Knowledge), 以及 <strong>计算零知识</strong>（Computational Zero Knowledge）。其中完全零知识是指验证者与模拟者的输出分布完全相等，统计零知识是指两者的输出分布统计上接近（Statistically close），而计算零知识就是说这两个输出分布在多项式时间内是不可区分的。</p>

<p>在Oded的survey中，他还有提到通常还需要要考虑到敌方（adversary）有辅助信息（auxiliary information）的情况。在这种情况下的零知识，称之为<strong>辅助输入零知识</strong>（auxiliary-input zero knowledge）。辅助输入零知识需要在定义2里用[View(S(x, z))]和[View((P V’(z))(x))] 来分别替代模拟者的输出分布和验证者的输出分布，其中z代表的是辅助信息。</p>

<p>除了以上的变体外，Oded的survey里提到了从对模拟者的要求出发衍生的一些变体， 其中一个就是要求有一个<strong>通用模拟者</strong>（Universal Simulator），这个模拟者拥有验证者B’的程序作为辅助输入。为了这个目的，我们需将定义2里的模拟者 S(x) 修改为 S(x, &lt;B’&gt;)，其中 &lt;B’&gt; 表示B’的程序(program)的描述。更进一步加强定义的话，我们还可以要求把验证者的程序作为一个黑箱（Black Box）或是神谕机（Oracle），称之为<strong>黑箱模拟</strong>（Black-box Simulation）。似乎最初大家都相信把B’的程序当作输入和把B’的程序作为黑箱使用对于零知识来说是没有区别的，不过Boaz Barak [3] 在2001年的论文给出了它们的区别。</p>

<p><strong>参考文献(References)</strong><br />
[1] Oded Goldreich. Zero-knowledge twenty years after its invention. Unpublished manuscript. 2002.<br />
[2] Rafail Ostrovsky. Foundations of Cryptography Draft Lecture Notes.<br />
[3] Boaz Barak. How to go beyond the black-box simulation barrier. FOCS 2011.</p>

    
  </div>
  
</div>
    </div>

  </body>
</html>
